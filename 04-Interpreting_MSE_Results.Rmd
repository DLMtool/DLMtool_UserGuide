
# (PART\*) Interpreting MSE Results  {-}

# Examining the MSE object
The MSE object contains all of the output from the MSE. In this chapter we will examine the MSE object in more detail.

First we will run an MSE so that we have an MSE object to work with. We will then briefly examine some of the contents of the MSE object. The chapters [Performance Metrics] and [Custom Performance Metrics] contain more information on the MSE object.

We create an OM based on the Blue Shark stock object and other built-in objects:
```{r}
OM <- new('OM', Blue_shark, Generic_Fleet, Imprecise_Biased, Perfect_Imp, nsim=200)
```

Note that we have increased the number of simulations from the default 48 to 200:
```{r}
OM@nsim
```

Let's choose an arbitrary set of MPs:
```{r}
MPs <- c("Fratio", "DCAC", "Fdem", "DD", "matlenlim") 
```

Set up parallel processing:
```{r, message=FALSE, warning=FALSE}
setup()
```

And run the MSE using parallel processing and save the output to an object called `BSharkMSE`:
```{r, cache=TRUE}
BSharkMSE <- runMSE(OM, MPs, parallel = TRUE)
```

```{r, include=FALSE}
nslots <- length(slotNames(BSharkMSE))
nnames <- length(names(BSharkMSE@OM))
```
The names of the slots in an object of class `MSE` can be displayed using the `slotNames` function:
```{r}
slotNames(BSharkMSE)
```
As you can see, `MSE` objects contain all of the information from the MSE, stored in `r nslots` slots.

## The First Six Slots
The first six slots contain information on the structure of the MSE.  For example the first slot (`Name`),  is a combination of the names of the `Stock`, `Fleet`, and `Obs` objects that were used in the MSE:
```{r}
BSharkMSE@Name
```
Other information in these first slots includes the number of historical years (`nyears`), the number of projection years (`proyears`), the number of name of the Management Procedures (`nMPs` and `MPs`), and the number of simulations (`nsim`).

## The `OM` Slot
The `OM` slot in the `MSE` object is a data frame that the values of the parameters used in the Operating Model:
```{r}
names(BSharkMSE@OM)
```
If you use the `dim` function to report the dimensions of the `OM` data frame, you'll notice that there are `r nnames` columns, corresponding to the `r nnames` parameters in the Operating Model, and `r BSharkMSE@nsim` rows, each corresponding to a single simulation of the MSE.

More information on the `MSE@OM` slot can be found in the help documentation: `class?MSE`

## The `Obs` Slot
The `Obs` slot contains another data frame, this one with `r ncol(BSharkMSE@Obs)` columns corresponding to the values drawn from the Observation model:
```{r}
names(BSharkMSE@Obs)
```

The `Obs` data frame also has `r BSharkMSE@nsim` rows, each corresponding to a single simulation.  More information on the `MSE@Obs` slot can be found in the help documentation: `class?MSE`

The information contained in the `OM` and `Obs` slots can be used to examine the sensitivity of the performance of Management Procedures with respect to different operating model and observation parameters.  This is discussed in more detail below. 

## The `B_BMSY` and `F_FMSY` Slots
The `B_BMSY` and `F_FMSY` are data frames containing the biomass relative to biomass at maximum sustainable yield $\left(\frac{B}{B_{MSY}}\right)$, and fishing mortality relative to the rate corresponding to maximum sustainable yield $\left(\frac{F}{F_{MSY}}\right)$ for each simulation, Management Procedure and projection year.

If we look at the class of the `B_BMSY` slot, we see that it is an `array`:
```{r}
class(BSharkMSE@B_BMSY)
```

Using the `dim` function we can see that it is a 3-dimensional array, with the size corresponding to the number of simulations (`nsim`), the number of Management Procedures (`nMPs`), and the number of projection years (`proyears`): 
```{r}
dim(BSharkMSE@B_BMSY)
```

This information can be used to calculate statistics relating to the performance of each Management Procedure with respect to these metrics.

For example, if you wish to look at the distribution of $\frac{B}{B_{MSY}}$ for the second Management Procedure (`r BSharkMSE@MPs[2]`), you could use the `boxplot` function:
```{r}
boxplot(BSharkMSE@B_BMSY[,2,], xlab="Year", ylab="B/BMSY")
```

This plot shows that the relative biomass for the stock generally increases through the projection period when the `r BSharkMSE@MPs[2]` method is used, with the median relative biomass increasing from about `r round(median(BSharkMSE@B_BMSY[,2,1]),2)` in the first year to `r round(median(BSharkMSE@B_BMSY[,2,BSharkMSE@proyears]),2)` in the final year. 

However, the distribution appears to have quite high variability, which suggests that although the method works well on average, the final biomass was very low in some simulations.


## The `B`, `FM`, `C` and `TAC` Slots
The `B`, `FM`, and `C` slots contain the information relating to the stock biomass, the fishing mortality rate, and the catch for each simulation, Management Procedure, and projection year.

Typically, the MSE model in the DLMtool does not include information on the absolute scale of the stock biomass or recruitment, and all results usually must be interpreted in a relativistic context. 

This is particularly true for the biomass (`B`) and catch (`C`) where the absolute values in the MSE results (other than 0!) have little meaning.  

The biomass can by made relative to $B_{MSY}$, as shown above. Alternatively, biomass can be calculated with respect to the unfished biomass $\left(B_0\right)$, from information stored in the `OM` slot.

The catch information is usually made relative to the highest long-term yield (mean over last five years of projection) for each simulation obtained from a fixed *F* strategy.  This information (`RefY`) can be found in the `OM` slot.

Alternatively, the catch can be made relative to the catch in last historical year (`CB_hist`; see below), to see how future catches are expected to change relative to the current conditions.

The TAC slot contains the TAC recommendation for each simulation, MP, and projection year. In cases where a TAC was not set (e.g for a size limit), the value will be NA. The values in TAC may be different to those in the catch (C) slot due to implementation error of the total catch limit. 

## The `SSB_hist`, `CB_hist`, and `FM_hist` Slots
The `SSB_hist`, `CB_hist`, and `FM_hist` slots contain information on the spawning stock biomass, the catch biomass, and the fishing mortality from the historical period (the `nyears` in the operating model).  

These data frames differ from the previously discussed slots as they are 4-dimensional arrays, with dimensions corresponding to the simulation, the age classes, the historical year, and the spatial areas. 

The `apply` function can be used to aggregate these data over the age-classes or spatial areas.

## The `Effort` Slot
The `Effort` slot is a 3-dimensional array containing information on the relative fishing effort (relative to last historical year, or current conditions) for each simulation, Management Procedure and projection year.

We can look at the distribution of fishing effort for each Management Procedure in the final year of the projection period:

```{r}
pyear <- BSharkMSE@proyears
boxplot(BSharkMSE@Effort[,, pyear], outline=FALSE, 
        names=BSharkMSE@MPs, ylab="Relative fishing effort")

```
```{r, include=FALSE}
rng <- round(range(apply(BSharkMSE@Effort[,, pyear], 2, median)[1:4]),2)
```
This plot shows that the median fishing effort in the final year ranges from `r rng[1]` to `r rng[2]` for the first four output control methods, and is constant for the input control method (`matlenlim`).

This is because the output control method adjusts the total allowable catch, which depending on the amount of available stock, also impacts the amount of fishing activity.  

The input control methods assume that fishing effort is held at constant levels in the future, although the catchability is able to randomly or systematically vary between years.  Furthermore, input control methods can also adjust the amount of fishing effort in each year. 


# Performance Metrics 
A key use of the DLMtool is to evaluate the trade-offs in the performance of different potential Management Procedures and to assist in the decision-making process as to which Management Procedure is most likely to satisfy the various management objectives under realistic range of uncertainty and variability in the system.  

## The Need for Performance Metrics
In order to evaluate the relative effectiveness of different Management Procedures, it is important that decision-makers have clearly-defined management objectives.  These management objectives can be incorporated into the MSE process in the form of performance metrics, which provide the yardstick with which to compare the relative performance of different management strategies.  

Fisheries managers are confronted with the difficult task of maximizing yield and ensuring the sustainability of the resource and the overall health of the marine environment.  The principal objectives of fisheries management could be described as ensuring sustainable harvests and viable fishing communities, while maintaining healthy ecosystems.  However, this simplistic view overlooks the fact that there are often conflicts in different management objectives and that there is rarely an optimal management approach that fully satisfies all management objectives (Punt, 2015).  Walters and Martell (2004) explain that the task of modern fisheries management is to identify the various trade-offs among conflicting objectives and decide how to balance them in a satisfactory way.

## Inevitable Trade-Offs
A typical trade-off is the abundance of the target species versus the catch.  Assuming no significant system-wide natural perturbations, a fish stock may be exploited sustainability if catches are set at low levels.  However, such economic under-utilization of the resource is often seen as undesirable.  Alternatively, high catches may produce immediate short-term benefits, but may result in long-term degradation, or perhaps collapse, of the stock.  

Additionally, there is often a trade-off between stock size and fishing effort, which results in lower catch rates (and lower profit) for individual fishers when a large number of fishers are active in the fishery (Walters and Martell, 2004).  Other common trade-offs include the age and size at first capture, either delaying harvest until individuals are fewer in number (due to natural mortality) but larger in size, or capturing a large number of small sized fish (Punt, 2015).  

When multiple objectives are considered, there is usually not a single optimum solution, and fisheries managers are faced with the difficult task of determining the most appropriate management action that satisfies the numerous management objectives and stakeholder interests (Punt, 2015).

### Operational Management Objectives 
A key strength of the MSE approach is that decision-makers are required to specify clear objectives, which can be classified as either “conceptual” or “operational” (Punt et al., 2014).  Conceptual objectives are typically high-level policy goals that may be broadly defined.  

However, in order to be included in an MSE, conceptual objectives must be translated into operational objectives (i.e., expressed as values for performance metrics).  Such operational objectives, or performance metrics, may consist of both a reference point (e.g., biomass some fraction of equilibrium unfished level) as well as a measure of the acceptable associated risk (e.g., less than 10% chance that biomass declines below this reference level).

It is not unusual that some of the management objectives are in conflict.  A key benefit of the MSE approach is to highlight these trade-offs among the different management objectives to guide the decision-making process.  However, in order for these trade-offs to be quantified, it is critically important that the performance metrics are quantifiable and thus able to be incorporated into the MSE framework (Punt, 2015). 

## Commonly used Performance Metrics 
Management strategy evaluation is a simulation exercise where the model can track the specific performance with perfect information, so it is possible to state performance objectives in specific terms that are consistent with the typical objectives of fisheries policies, such as: 

*	Biomass relative to unfished biomass $\left(B_0\right)$ or biomass at maximum sustainable yield $\left(B_{MSY}\right)$.
*	Fishing mortality rate relative to fishing at maximum sustainable yield $\left(F_{MSY}\right)$.
*	Yield (short-term or long-term) of a particular management strategy relative to the yield if the fishery were being exploited at $F_{MSY}$.
*	Inter-annual variability in yield or effort (e.g., fluctuations in yield from year to year).  

Because the management strategy evaluation runs many simulations of the fisheries performance under each management strategy being tested, the performance can be stated probabilistically, such as the specific probability of biomass being above or below a specific biomass threshold or target.  

### Fishing Mortality
For example, the management strategies can be ranked by the likelihood of overfishing to occur, where the probability of overfishing is measured by the proportion of simulation runs where the fishing mortality rate (*F*) under a specific management strategy is higher than the *F* that is expected to produce the maximum sustainable yield.  
Management strategies that have a lower probability of overfishing occurring are typically preferable to those that frequently cause excessive fishing mortality rates.  If there are 1,000 simulation runs for each management strategy over a 50-year projection period, then the probability of overfishing could be based on the proportion where *F* is greater than (or less than) $F_{MSY}$ over all years or any subset of years (e.g., probability of overfishing in years 41-50 of the 50-year projection period). 

### Stock Biomass
Another common performance metric is the probability that the stock biomass is above or below some biological reference point.  For example, a minimum performance limit may be half the biomass at maximum sustainable yield (0.5 BMSY), and the performance of the management strategies can be ranked by the probability of the stock remaining above this level.  

Management strategies that fail to maintain biomass above this limit with a high priority may be considered too risky and therefore excluded from further examination.  

### Additional Performance Metrics
There may be other performance metrics that are of interest to fishery managers and stakeholders.  Stakeholder participation is critical when developing performance metrics to evaluate different biological scenarios or management strategies in a MSE.  Furthermore, it is important that the performance metrics, together with any acceptable risk thresholds are identified and agreed upon before the MSE is conducted.


## Performance Metrics Methods
DLMtool includes a set of functions, of class `PM`, for calculating Performance Metrics. The available `PM` functions (referred to as PMs) can be found using the `avail` function:

```{r}
avail("PM")
```

The PMs are used for summarizing the performance of the management procedures and plotting the results in trade-off plots. 

Here we briefly describe the built-in Performance Metrics functions and demonstrate their use. Advanced DLMtool users can develop their own `PM` methods, see the [Custom Performance Metrics] chapter for details.

Functions of class `PM` are used on an object of class `MSE` (i.e the object returned by `runMSE`), and return an object of class `PMobj`. Most of the time the `PM` functions are used internally in the `summary` or plotting functions, and it will not be neccessary to acess the `PMobj` directly. 

To demonstrate the `PM` functions we first run a quick example MSE:

```{r, include=FALSE}
MSE <- runMSE(silent=TRUE)
```

```{r, eval=FALSE}
MSE <- runMSE()
```


### Overview of the `PM` Functions

We will use the `P50` function to demonstrate the `PM` methods. Help documentation on the PM methods can be accessed in the usual way: `?P50`.

The `P50` PM method calculates the probability that spawning biomass is above half of the spawning biomass that results in maximum sustainable yield $\left(\text{SB} > 0.5\text{SB}_\text{MSY}\right)$. 

```{r P50int, include=FALSE}
p50 <- P50(MSE)
```

Applying the `P50` function to our `MSE` object results in the following output:
```{r P50}
P50(MSE)
```

We can see that the `PM` function calculated, for the 6 MPs in the `MSE` object, the probability $\text{SB} > 0.5\text{SB}_\text{MSY}$ for all `r MSE@proyears` projection years. 

The `PM` function prints out a summary table of the performance metrics statistics for the first 10 simulations and the last simulation (`r MSE@nsim` in this case) for each MP. The final line shows the overall probability of the performance metric, i.e the average performance across all simulations. 

We will look into this output in a little more detail.

We can see that the first MP is `r MSE@MPs[1]` and the performance statistics for the first and second simulations are `r p50@Prob[1,1]` and `r p50@Prob[2,1]`. How have these values been calculated and what do they mean?

Let's first plot the spawning biomass relative to BMSY for the first two simulations of the `AvC` MP:

```{r}
par(mfrow=c(1,2))
plot(1:MSE@proyears, MSE@B_BMSY[1,1,], type='l', 
     xlab="Years", ylab="B/BMSY", lwd=2, bty="l", ylim=c(0,2),
     main="MP = 'AvC'; Sim =  1")
abline(h=0.5, lty=3)

plot(1:MSE@proyears, MSE@B_BMSY[2,1,], type='l', 
     xlab="Years", ylab='', lwd=2, bty="l", ylim=c(0,2),
     main="MP = 'AvC'; Sim =  2")
abline(h=0.5, lty=3)
```

Now we will calculate fraction of years where spawning biomass is above 0.5 $\text{SB}_\text{MSY}$ for the first and second simulations:

```{r}
mean(MSE@B_BMSY[1,1,] > 0.5) # first simulation
mean(MSE@B_BMSY[2,1,] > 0.5) # second simulation
# identical to: 
# sum(MSE@B_BMSY[1,1,] > 0.5)/MSE@proyears
# sum(MSE@B_BMSY[2,1,] > 0.5)/MSE@proyears
```

Notice how the performance statistics for each simulation correspond with the plot shown above? 

The overall performance is then calculated by the probability over all simulations, i.e for the first MP `r MSE@MPs[1]`:
```{r}
mean(MSE@B_BMSY[,1,]>0.5)
```

And for `r MSE@nMPs` MPs:
```{r}
round(apply(MSE@B_BMSY >0.5, 2, mean),2)
```
which, reassuringly, is the same as the output of the `P50` function.

### Customizing the `PM` Functions

The `PM` functions allow for very quick calculation of performance metrics. For example, suppose that instead of calculating performance over all projection years, we are only interested in the long-term performance, say over the last 10 years. This can be easily achieved using the `Yrs` argument in the `PM` function:

```{r}
P50(MSE, Yrs=c(41,50))
```

Or the first 10 years:

```{r}
P50(MSE, Yrs=c(1,10))
```

The other biomass Performance Metric functions work in the same way:

```{r}
P10(MSE) # probability SB > 0.1SB_MSY for all years
P100(MSE) # probability SB > SB_MSY for all years
```

Long-term, short-term and overall average yield are calculated using `LTY`, `STY` and `Yield` respectively:

```{r}
LTY(MSE)
STY(MSE)
Yield(MSE)
```

The `PNOF` PM function calculates the probability of not overfishing:
```{r }
PNOF(MSE)
```


Finally, the average annual variability in yield (AAVY) can be calculated with the `AAVY` function:

```{r}
AAVY(MSE)
```

By default the `AAVY` PM function calculates the probability that AAVY is less than 20%. This reference level can easily be modified using the `Ref` argument:

```{r}
AAVY(MSE, Ref=0.15) # prob. AAVY < 15%
AAVY(MSE, Ref=0.30) # prob. AAVY < 30%
```

The other `PM` functions also have the `Ref` argument which can be used in the same way. For example, you may notice that the `P50` and `P100` functions are identical except for the value of the `Ref` argument:

```{r}
args(P50)
args(P100)
```

It follows then that it is very simple to calculate a custom performance metric based on the built-in `PM` functions. For example, suppose we wanted to calculate the probability that spawning biomass was above 5% of BMSY. This can be achieved by using any of the biomass-based `PM` functions and modifying the `Ref` argument:

```{r}
P50(MSE, Ref=0.05)
P100(MSE, Ref=0.05)
```

More information on customizing `PM` functions can be found in the [Custom Performance Metrics] chapter.

In the next section we will demonstrate using `PM` functions in summarizing and plotting functions.

## Summarizing Management Procedure Performance
The [Examining the MSE Results] chapter introduced the `summary` function for `MSE` objects and some of the plotting functions for visualizing the results. Here we demonstrate how the `PM` functions can be used in the `summary` function and the trade-off plots:

### `summary` Table
The `summary` function provides information on the performance of the Management Procedures with respect to the performance metrics. By default, `summary` includes the `PNOF`, `P50`, `AAVY` and `LTY` performance metrics:

```{r}
summary(MSE)
```

It is straightforward to include other `PM` functions by adding the names of the `PM` functions, for example:

```{r}
summary(MSE, 'P100', 'Yield')
```

or all available `PM` functions:
```{r}
summary(MSE, avail('PM'))
```

The `summary` function returns a data frame which can be useful for referring to the PM results elsewhere in the analysis. For example,
```{r}
Results <- summary(MSE, avail('PM'), silent=TRUE) # silent=TRUE to hide print-out to console
Results$Yield # access the PM results
```


### Trade-Off Plots 

The `TradePlot` function takes an object of class `MSE` and the names of `PM` functions (at least 2) to produce a trade-off plot. For example:

```{r}
TradePlot(MSE) # default plot 
```

The order of the `PM` function names determines plotting on the x and y axes. For example:

```{r}
TradePlot(MSE, 'P50' ,'LTY')  # x = P50, y  = LTY
TradePlot(MSE, 'LTY' ,'P50')  # x = LTY, y = P50
```

The PMs are recycled if an odd number are provided:
```{r}
TradePlot(MSE, 'P50' ,'LTY', 'STY') 
```

The `Lims` argument is used to set the vertical and horizontal acceptable risk thresholds and are interpreted in the same order as the names of the `PM` functions. For example:

```{r}
TradePlot(MSE, 'P50' ,'LTY', Lims=c(0.8, 0))  # 80% minimum acceptable risk for P50, no minimum for LTY
TradePlot(MSE, 'P50' ,'STY', 'P100', 'LTY', Lims=c(0.8, 0, 0.5, 0))  # 80% minimum acceptable risk for P50, 50% for P100, no minimum for STY and LTY
```

```{r include=FALSE}
res <- TradePlot(MSE, 'P50' ,'STY', 'P100', 'LTY', Lims=c(0.8, 0, 0.5, 0), Show=FALSE)
```
The `TradePlot` function returns a data frame with the results of the performance metrics, and a column indicating if an MP has met minimum performance criteria for **all** performance metrics. In the previous example, `r sum(res$Results$Satisificed)` MPs (`r res$Results$MP[res$Results$Satisificed]`) met the minimum performance criteria for all four performance metrics.

The `TradePlot` function can be used to make a variety of custom trade-off plots. For example, the `Tplot`, `Tplot2`, and `Tplot3` functions all use this function to produce different trade-off plots:

```{r}
Tplot
Tplot(MSE)
```

Similarly, we can easily reproduce `NOAA_plot` using the `Tradeplot` function:

```{r}
NOAA_plot(MSE)
TradePlot(MSE, Lims=c(0.5, 0, 0.8, 0.5), 
          PMlist=list("PNOF", "LTY", "P50", "AAVY"), Refs=list(AAVY=0.15))
```

See the [Plotting MSE Results] section for examples on DLMtool plotting functions for the MSE object. 

Advanced users may wish to develop their own plotting and summary functions. See the [Custom Performance Metrics] section for more details on this. 


# Value of Information
The Value of Information (VOI) functions have been designed to explore the sensitivity of the performance of the Management Procedures to variability in the observation processes and operating model parameters.

There are several VOI functions in DLMtool. 

The `VOI` function generates two plots, one corresponding to the operating model parameters, and the other to the observation model parameters, showing the gradient in long-term yield with respect to the individual parameters:
```{r, fig.height=9, fig.width=9}
VOI(MSE)
```

The `VOIplot` function shows something similar, but has an argument to specify either the Observation or Operating Model parameters:
```{r, fig.height=9, fig.width=9}
# Observation Parameters
VOIplot(MSE, nMP=5)

# OM Parameters
VOIplot(MSE, Par="OM", nMP=5)
```

By default, the `VOIplot` function only shows the four Management Procedures with the greatest sensitivity.  Here we've made it show all five methods using the `nMP` argument.

In this example we can see that the `Fratio` method is particularly sensitive to bias in the current estimate of abundance, and over-estimates of the current abundance result in very low long-term yield (probably do to collapse of the stock).  The DCAC method appears most sensitive to bias in the estimated catch.

We can also use the `VOIplot` function to look at the sensitivity with respect to the final biomass by specifying the `YVar` argument:
```{r, fig.height=9, fig.width=9}
VOIplot(MSE, Par="OM", nMP=5, YVar="B")
```

This result shows, perhaps unsurprisingly, that the final biomass is often strongly sensitive to the initial depletion, particularly for the DCAC and matlenlim methods.  

The `VOIplot2` function is an updated version of `VOIplot` that uses the `PM` functions and plots the Value of Information for a single MP:

```{r}
VOIplot2(MSE)
VOIplot2(MSE, type="OM")
```

and with a different MP and performance metric:
```{r}
VOIplot2(MSE, MP="DCAC", PM="P100")
VOIplot2(MSE, MP="DCAC", type="OM", PM="P100")
```


The `VOI2` function relates the operating model parameters and parameters of the observation model to relative yield (yield over last 5 years of projection relative to a 'best F' scenario that maximizes yield.

```{r, fig.height=9, fig.width=9}
VOI2(MSE)
```

`VOI2` assumes that relative cost for each type of improvement in data is linearly related to the number of samples (e.g. nCAAobs) or square function of improved precision and bias e.g.: relative $\text{cost}= \frac{1}{(\text{newCV}/\text{oldCV})^2}$

The VOI features of DLMtool are continuing to be developed and more VOI functions will be added soon. 


